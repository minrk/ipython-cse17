{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawling Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook crawls links on Wikipedia\n",
    "and visualizes the graph with NetworkX and d3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from d3networkx import ForceDirectedGraph, EventfulGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ipyparallel as parallel\n",
    "rc = parallel.Client()\n",
    "lbv = rc.load_balanced_view()\n",
    "rc.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px --local\n",
    "\n",
    "import requests\n",
    "try:\n",
    "    import requests_cache\n",
    "except ImportError:\n",
    "    print(\"no cache\")\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "wiki_pat = re.compile(r'^/wiki/([^:]*)$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def links_for_page(title):\n",
    "    page = BeautifulSoup(requests.get('http://en.wikipedia.org/wiki/%s' % title).text)\n",
    "    links = page.find(\"div\", id=\"content\").findAll(\"a\", href=wiki_pat)\n",
    "    \n",
    "    titles = []\n",
    "    for link in links:\n",
    "        title = wiki_pat.match(link['href']).group(1)\n",
    "        titles.append(title)\n",
    "        \n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_node(g, label, **kwargs):\n",
    "    \"\"\"add a node to a graph, with some default fill and color\"\"\"\n",
    "    kwargs.setdefault('fill', '#ccc')\n",
    "    kwargs.setdefault('color', 'black')\n",
    "    g.add_node(label, label=label, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = 200\n",
    "\n",
    "def add_links(graph, src, links):\n",
    "    \"\"\"Add links from src to links in graph\"\"\"\n",
    "    new_nodes = []\n",
    "    add_node(graph, src)\n",
    "    n = len(links)\n",
    "    for i,link in enumerate(links):\n",
    "        if link not in graph:\n",
    "            new_nodes.append(link)\n",
    "            add_node(graph, link)\n",
    "            \n",
    "        graph.add_edge(src, link, distance=d)\n",
    "    return new_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def wikipedia_graph(lbview, root, limit=32, in_degree_limit=3):\n",
    "    \"\"\"build a graph by crawling Wikipedia from a root page\n",
    "    \n",
    "    The visualized graph will be limited to pages linked from several other pages\n",
    "    \"\"\"\n",
    "    graph = nx.DiGraph()\n",
    "    egraph = EventfulGraph()\n",
    "\n",
    "    graph_widget = ForceDirectedGraph(egraph, width=800, height=600)\n",
    "    display(graph_widget)\n",
    "    \n",
    "    add_node(graph, root)\n",
    "    add_node(egraph, root, r=16, fill='#aef')\n",
    "    surface = [root]\n",
    "    while len(egraph) < limit:\n",
    "        surface = [ node for node in graph if graph.out_degree(node) == 0 ]\n",
    "        amr = lbview.map_async(links_for_page, surface)\n",
    "        for i, links in enumerate(amr):\n",
    "            src = surface[i]\n",
    "            links = links[:20]\n",
    "            add_links(graph, src, links)\n",
    "            for node in links:\n",
    "                if graph.in_degree(node) >= in_degree_limit:\n",
    "                    path = nx.shortest_path(graph, root, node)\n",
    "                    prv = root\n",
    "                    for nxt in path[1:]:\n",
    "                        if nxt not in egraph:\n",
    "                            add_node(egraph, nxt)\n",
    "                        egraph.add_edge(prv, nxt, distance=d)\n",
    "                        egraph.node[nxt]['r'] = min(3 * graph.in_degree(nxt), 24)\n",
    "                        prv = nxt\n",
    "                    for parent in graph.predecessors(node):\n",
    "                        if parent in egraph:\n",
    "                            egraph.add_edge(parent, node, distance=d)\n",
    "                    egraph.node[node]['r'] = min(3 * graph.in_degree(node), 24)\n",
    "                    for child in graph.successors(node):\n",
    "                        if child in egraph:\n",
    "                            egraph.add_edge(node, child, distance=d)\n",
    "                            egraph.node[child]['r'] = min(3 * graph.in_degree(child), 24)\n",
    "                    time.sleep(0.3)\n",
    "                if len(egraph) > limit:\n",
    "                    return graph, egraph\n",
    "            print('%s: %i' % (src, len(graph)))\n",
    "            sys.stdout.flush()\n",
    "    return graph, egraph\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g, eg = wikipedia_graph(lbv, 'University_of_Southampton', limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g, eg = wikipedia_graph(lbv, 'Computer_simulation', limit=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
