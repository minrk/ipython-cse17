{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAG Dependencies\n",
    "\n",
    "Often, parallel workflow is described in terms of a [Directed Acyclic\n",
    "Graph](http://en.wikipedia.org/wiki/Directed_acyclic_graph) or DAG. A\n",
    "popular library for working with Graphs is\n",
    "[NetworkX](http://networkx.lanl.gov/). Here, we will walk through a demo\n",
    "mapping a nx DAG to task dependencies.\n",
    "\n",
    "The full script that runs this demo can be found in `code/dagdeps.py`.\n",
    "\n",
    "## Why are DAGs good for task dependencies?\n",
    "\n",
    "The 'G' in DAG is 'Graph'. A Graph is a collection of **nodes** and\n",
    "**edges** that connect the nodes. For our purposes, each node would be a\n",
    "task, and each edge would be a dependency. The 'D' in DAG stands for\n",
    "'Directed'. This means that each edge has a direction associated with\n",
    "it. So we can interpret the edge (a,b) as meaning that b depends on a,\n",
    "whereas the edge (b,a) would mean a depends on b. The 'A' is 'Acyclic',\n",
    "meaning that there must not be any closed loops in the graph. This is\n",
    "important for dependencies, because if a loop were closed, then a task\n",
    "could ultimately depend on itself, and never be able to run. If your\n",
    "workflow can be described as a DAG, then it is impossible for your\n",
    "dependencies to cause a deadlock.\n",
    "\n",
    "## A Sample DAG\n",
    "\n",
    "Here, we have a very simple 5-node DAG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ipyparallel as parallel\n",
    "\n",
    "rc = parallel.Client()\n",
    "view = rc.load_balanced_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ar = view.apply_async(time.sleep, 3)\n",
    "with view.temp_flags(after=ar, timeout=2):\n",
    "    ar2 = view.apply_async(time.sleep, 2)\n",
    "\n",
    "%time ar2.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ar2.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# add 5 nodes, labeled 0-4:\n",
    "map(G.add_node, range(5))\n",
    "# 1,2 depend on 0:\n",
    "G.add_edge(0,1)\n",
    "G.add_edge(0,2)\n",
    "# 3 depends on 1,2\n",
    "G.add_edge(1,3)\n",
    "G.add_edge(2,3)\n",
    "# 4 depends on 1\n",
    "G.add_edge(1,4)\n",
    "\n",
    "# now draw the graph:\n",
    "pos = { 0 : (0,0), 1 : (1,1), 2 : (-1,1),\n",
    "        3 : (0,2), 4 : (2,2)}\n",
    "nx.draw(G, pos, edge_color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With NetworkX, an arrow is just a fattened bit on the edge. Here, we can\n",
    "see that task 0 depends on nothing, and can run immediately. 1 and 2\n",
    "depend on 0; 3 depends on 1 and 2; and 4 depends only on 1.\n",
    "\n",
    "A possible sequence of events for this workflow:\n",
    "\n",
    "0.  Task 0 can run right away\n",
    "1.  0 finishes, so 1,2 can start\n",
    "2.  1 finishes, 3 is still waiting on 2, but 4 can start right away\n",
    "3.  2 finishes, and 3 can finally start\n",
    "\n",
    "Further, taking failures into account, assuming all dependencies are run\n",
    "with the default `success=True,failure=False`, the following cases\n",
    "would occur for each node's failure:\n",
    "\n",
    "0.  fails: all other tasks fail as Impossible\n",
    "1.  2 can still succeed, but 3,4 are unreachable\n",
    "2.  3 becomes unreachable, but 4 is unaffected\n",
    "3.  and 4. are terminal, and can have no effect on other nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, we have a function that generates a random DAG with a given number of nodes and edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "def random_dag(nodes, edges):\n",
    "    \"\"\"Generate a random Directed Acyclic Graph (DAG) with a given number of nodes and edges.\"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    for i in range(nodes):\n",
    "        G.add_node(i)\n",
    "    while edges > 0:\n",
    "        a = randint(0,nodes-1)\n",
    "        b=a\n",
    "        while b==a:\n",
    "            b = randint(0,nodes-1)\n",
    "        G.add_edge(a,b)\n",
    "        if nx.is_directed_acyclic_graph(G):\n",
    "            edges -= 1\n",
    "        else:\n",
    "            # we closed a loop!\n",
    "            G.remove_edge(a,b)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So first, we start with a graph of 32 nodes, with 128 edges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G = random_dag(32,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.draw(G, pos=nx.spring_layout(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomwait():\n",
    "    import time, random\n",
    "    tic = time.time()\n",
    "    time.sleep(random.random())\n",
    "    return time.time() - tic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a dict of jobs matching the nodes on the graph, \n",
    "we can start submitting jobs, and linking up the dependencies. \n",
    "Since we don’t know a job’s msg_id until it is submitted, \n",
    "which is necessary for building dependencies, \n",
    "it is critical that we don’t submit any jobs before other jobs it may depend on. \n",
    "Fortunately, NetworkX provides a topological_sort() method which ensures exactly this. \n",
    "It presents an iterable, that guarantees that when you arrive at a node, \n",
    "you have already visited all the nodes it on which it depends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jobs = {}\n",
    "\n",
    "# in reality, each job would presumably be different\n",
    "# randomwait is just a function that sleeps for a random interval\n",
    "for node in G:\n",
    "     jobs[node] = randomwait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a dict of jobs matching the nodes on the graph, we can\n",
    "start submitting jobs, and linking up the dependencies. Since we don't\n",
    "know a job's msg_id until it is submitted, which is necessary for\n",
    "building dependencies, it is critical that we don't submit any jobs\n",
    "before other jobs it may depend on. Fortunately, NetworkX provides a\n",
    "`topological_sort` method which ensures exactly this. It presents an\n",
    "iterable, that guarantees that when you arrive at a node, you have\n",
    "already visited all the nodes it on which it depends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for node in nx.topological_sort(G):\n",
    "    # get list of AsyncResult objects from nodes\n",
    "    # leading into this one as dependencies\n",
    "    deps = [ results[n] for n in G.predecessors(node) ]\n",
    "    # submit and store AsyncResult object\n",
    "    with view.temp_flags(after=deps, block=False):\n",
    "         results[node] = view.apply_async(jobs[node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "view.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_tree(G, results):\n",
    "    \"\"\"Validate that jobs executed after their dependencies.\"\"\"\n",
    "    for node in G:\n",
    "        started = results[node].metadata.started\n",
    "        for parent in G.predecessors(node):\n",
    "            finished = results[parent].metadata.completed\n",
    "            assert started > finished, \"%s should have happened after %s\" % (node, parent)\n",
    "\n",
    "validate_tree(G, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.dates import date2num\n",
    "\n",
    "from matplotlib.cm import gist_rainbow\n",
    "\n",
    "pos = {}; colors = {}\n",
    "\n",
    "xmin = ymin = np.inf\n",
    "xmax = ymax = 0\n",
    "\n",
    "for node in G:\n",
    "    md = results[node].metadata\n",
    "    start = date2num(md.started)\n",
    "    if start < xmin:\n",
    "        xmin = start\n",
    "    if start > xmax:\n",
    "        xmax = start\n",
    "    runtime = date2num(md.completed) - start\n",
    "    if runtime < ymin:\n",
    "        ymin = runtime\n",
    "    if runtime > ymax:\n",
    "        ymax = runtime\n",
    "    pos[node] = (start, runtime)\n",
    "    colors[node] = md.engine_id\n",
    "\n",
    "nx.draw(G, pos, node_list=colors.keys(), node_color=colors.values(),\n",
    "    cmap=gist_rainbow)\n",
    "\n",
    "dx = xmax - xmin\n",
    "dy = ymax - ymin\n",
    "plt.xlim(xmin-0.1*dx, xmax+0.1*dx)\n",
    "plt.ylim(ymin-0.1*dy, ymax+0.1*dy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time started on x, runtime on y, and color-coded by engine-id (in this case there were four engines). Edges denote dependencies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
